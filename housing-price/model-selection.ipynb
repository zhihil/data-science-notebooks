{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model-selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3blgptduImo"
      },
      "source": [
        "# Predicting Housing Prices, Model Selection\n",
        "## Overview\n",
        "\n",
        "The dataset is a Housing Prices dataset found [here](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview) \n",
        "\n",
        "We will build a regression model to predict housing prices and submit to the competition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4H8JsNbuPbC"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DuEX0K4uGEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a040191-4395-4164-ef15-4751c6dcdb76"
      },
      "source": [
        "!pip install -U scikit-learn\n",
        "!pip install -U statsmodels\n",
        "!pip show scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (2.1.0)\n",
            "Requirement already up-to-date: statsmodels in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.1 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
            "Name: scikit-learn\n",
            "Version: 0.24.2\n",
            "Summary: A set of python modules for machine learning and data mining\n",
            "Home-page: http://scikit-learn.org\n",
            "Author: None\n",
            "Author-email: None\n",
            "License: new BSD\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: joblib, threadpoolctl, numpy, scipy\n",
            "Required-by: yellowbrick, textgenrnn, sklearn, sklearn-pandas, mlxtend, lightgbm, librosa, imbalanced-learn, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyLX5CRcuOcS",
        "outputId": "04f6a6e9-5528-4e4e-db8f-c2dbaf158bcb"
      },
      "source": [
        "# Mount so that we can access files on Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGQCr8KMuQXh"
      },
      "source": [
        "# Loading the data\n",
        "import pandas as pd\n",
        "\n",
        "workdir = \"/content/drive/My Drive/Colab Notebooks/housing-prices/\"\n",
        "train_filepath = workdir + \"train.csv\"\n",
        "test_filepath = workdir + \"test.csv\"\n",
        "\n",
        "raw_data = pd.read_csv(train_filepath, index_col=\"Id\")\n",
        "X_test = pd.read_csv(test_filepath, index_col=\"Id\")\n",
        "\n",
        "target_col = 'SalePrice'\n",
        "X = raw_data.drop(target_col, axis=1)\n",
        "y = raw_data[target_col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "WcPVQQbKuSOt",
        "outputId": "d2aecc1f-01b6-414a-d810-b32208e9d068"
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    MSSubClass MSZoning  LotFrontage  ...  SaleType SaleCondition SalePrice\n",
              "Id                                    ...                                  \n",
              "1           60       RL         65.0  ...        WD        Normal    208500\n",
              "2           20       RL         80.0  ...        WD        Normal    181500\n",
              "3           60       RL         68.0  ...        WD        Normal    223500\n",
              "4           70       RL         60.0  ...        WD       Abnorml    140000\n",
              "5           60       RL         84.0  ...        WD        Normal    250000\n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TYoKhE2uYD5"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "numerical_transformer = Pipeline(\n",
        "    steps=[('num_impute', SimpleImputer(strategy='mean')),\n",
        "           ('standardize', StandardScaler())]\n",
        ")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[('cat_impute', SimpleImputer(strategy='most_frequent')),\n",
        "           ('ord_encoding', OneHotEncoder(handle_unknown=\"ignore\"))]\n",
        ")\n",
        "\n",
        "# Using a subset of the features because using all 79 features will cause an explosion in MSE\n",
        "baseline_num_cols = ['YearBuilt', 'OverallQual', 'OverallCond', 'LotArea', '1stFlrSF', \n",
        "                     '2ndFlrSF', 'BedroomAbvGr', 'WoodDeckSF', 'OpenPorchSF']\n",
        "baseline_cat_cols = ['LotFrontage', 'KitchenQual', 'Heating', 'RoofStyle', 'RoofMatl',\n",
        "                     'BldgType', 'Neighborhood']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('num', numerical_transformer, baseline_num_cols),\n",
        "                  ('cat', categorical_transformer, baseline_cat_cols)]\n",
        ")\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                       ('model', model)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SdClQKotudlm",
        "outputId": "55f0b92f-b5ac-49b1-bb70-99633cbad79a"
      },
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=None, \n",
        "                        train_sizes=np.linspace(.1, 1.0, 5), scoring=None):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, \n",
        "                                                            n_jobs=n_jobs,\n",
        "                                                            train_sizes=train_sizes, \n",
        "                                                            scoring=scoring)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                     color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    \n",
        "    return train_scores, test_scores\n",
        "\n",
        "def pretty_learning_curve(clf, X, y, scoring, train_sizes):\n",
        "  \n",
        "  plt.xlabel(\"Dataset Size\")\n",
        "  plt.ylabel(\"Score\")\n",
        "  train_scores, valid_scores = plot_learning_curve(clf, \"Learning Curve\", X, y, \n",
        "                                                   train_sizes=train_sizes, scoring=scoring)\n",
        "  plt.show()\n",
        "\n",
        "  for train_size, scores in zip(train_sizes, train_scores):\n",
        "    print(\"Train score - size %3d - mean %10f - scores %60s\" % \n",
        "          (train_size, np.mean(scores), str(scores)))\n",
        "\n",
        "  print()\n",
        "\n",
        "  for train_size, scores in zip(train_sizes, valid_scores):\n",
        "    print(\"Valid score - size %3d - mean %10f - scores %60s\" % \n",
        "          (train_size, np.mean(scores), str(scores)))\n",
        "\n",
        "X_baseline = X[baseline_num_cols + baseline_cat_cols]\n",
        "y_baseline = y\n",
        "\n",
        "train_sizes = [100 * i + 1 for i in range(0, 12)]\n",
        "pretty_learning_curve(pipe, X_baseline, y_baseline, \n",
        "                      scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=train_sizes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train score - size   1 - mean   0.000000 - scores                                             [0. 0. 0. 0. 0.]\n",
            "Train score - size 101 - mean 77904081.246537 - scores [75892218.06283794 78407047.04246159 78407047.04246159 78407047.04246159\n",
            " 78407047.04246159]\n",
            "Train score - size 201 - mean 196675798.059901 - scores [2.53008662e+08 1.82592582e+08 1.82592582e+08 1.82592582e+08\n",
            " 1.82592582e+08]\n",
            "Train score - size 301 - mean 296766459.928973 - scores [4.83198011e+08 2.61245135e+08 2.46463051e+08 2.46463051e+08\n",
            " 2.46463051e+08]\n",
            "Train score - size 401 - mean 343854198.312451 - scores [5.56290505e+08 3.26301325e+08 2.78893054e+08 2.78893054e+08\n",
            " 2.78893054e+08]\n",
            "Train score - size 501 - mean 407754320.073171 - scores [5.41954429e+08 3.75227397e+08 3.73863258e+08 3.73863258e+08\n",
            " 3.73863258e+08]\n",
            "Train score - size 601 - mean 493515588.588719 - scores [5.34784205e+08 4.31166456e+08 4.88932462e+08 5.06347410e+08\n",
            " 5.06347410e+08]\n",
            "Train score - size 701 - mean 539454995.680070 - scores [5.97900568e+08 4.86321995e+08 5.51681161e+08 5.30685627e+08\n",
            " 5.30685627e+08]\n",
            "Train score - size 801 - mean 566308638.033207 - scores [6.35040047e+08 5.28610948e+08 5.80506636e+08 5.43692780e+08\n",
            " 5.43692780e+08]\n",
            "Train score - size 901 - mean 618024940.020492 - scores [7.02972528e+08 5.61495319e+08 6.34980897e+08 6.02807468e+08\n",
            " 5.87868489e+08]\n",
            "Train score - size 1001 - mean 606040738.616356 - scores [6.77747006e+08 5.54106217e+08 6.18787316e+08 5.88418360e+08\n",
            " 5.91144793e+08]\n",
            "Train score - size 1101 - mean 618414909.910031 - scores [6.88620389e+08 5.62712586e+08 6.21782253e+08 6.01533689e+08\n",
            " 6.17425631e+08]\n",
            "\n",
            "Valid score - size   1 - mean 7438995024.889041 - scores [8.10693519e+09 7.22216079e+09 8.15013284e+09 6.32104492e+09\n",
            " 7.39470138e+09]\n",
            "Valid score - size 101 - mean 3199231878.435224 - scores [1.69998573e+09 4.17758066e+09 3.76345354e+09 2.43225130e+09\n",
            " 3.92288815e+09]\n",
            "Valid score - size 201 - mean 1654652143.374997 - scores [1.25025409e+09 1.70506746e+09 1.58905071e+09 1.08950558e+09\n",
            " 2.63938287e+09]\n",
            "Valid score - size 301 - mean 1409727499.940482 - scores [1.07572844e+09 1.59309447e+09 1.30982802e+09 9.88440120e+08\n",
            " 2.08154645e+09]\n",
            "Valid score - size 401 - mean 1339560227.192771 - scores [8.61351487e+08 1.65396828e+09 1.23471126e+09 9.04285979e+08\n",
            " 2.04348413e+09]\n",
            "Valid score - size 501 - mean 1311329485.858643 - scores [9.98429080e+08 1.60689472e+09 1.02787310e+09 8.49146417e+08\n",
            " 2.07430411e+09]\n",
            "Valid score - size 601 - mean 1284904726.498672 - scores [1.05837873e+09 1.42167473e+09 1.00702807e+09 1.00028681e+09\n",
            " 1.93715529e+09]\n",
            "Valid score - size 701 - mean 1266719769.563505 - scores [1.01934994e+09 1.28062637e+09 1.00042825e+09 1.10204094e+09\n",
            " 1.93115335e+09]\n",
            "Valid score - size 801 - mean 1218224831.070153 - scores [9.32072866e+08 1.26616470e+09 9.88346089e+08 1.02282193e+09\n",
            " 1.88171857e+09]\n",
            "Valid score - size 901 - mean 1226027562.214463 - scores [7.69804248e+08 1.40694100e+09 9.82760142e+08 1.01657916e+09\n",
            " 1.95405326e+09]\n",
            "Valid score - size 1001 - mean 1211689057.864617 - scores [7.75700173e+08 1.35899188e+09 9.75663918e+08 1.01809348e+09\n",
            " 1.92999584e+09]\n",
            "Valid score - size 1101 - mean 1258073182.805199 - scores [7.27018804e+08 1.40007232e+09 9.89306591e+08 1.22035687e+09\n",
            " 1.95361133e+09]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0CqPfQgu2Oc"
      },
      "source": [
        "global_random_state=0\n",
        "global_valid_size=0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZVJfXa6u0b0",
        "outputId": "7cd54cb4-4d98-4e84-a2f8-9a1bfb562dc7"
      },
      "source": [
        "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def score_classifier(pipe, X, y, cv_num=10, n_repeats=5):\n",
        "  cv_strategy = RepeatedKFold(n_splits=cv_num, n_repeats=n_repeats, \n",
        "                              random_state=global_random_state)\n",
        "  scoring_strategy = make_scorer(mean_squared_error)\n",
        "  score = cross_val_score(pipe, X, y, cv=cv_strategy, \n",
        "                          n_jobs=-1, scoring=scoring_strategy)\n",
        "  return np.mean(score), score\n",
        "\n",
        "class Evaluator():\n",
        "  def fit(self, pipe, X, y):\n",
        "    self.baseline = score_classifier(pipe, X, y)[0]\n",
        "    return self\n",
        "\n",
        "  def evaluate(self, pipe, X, y):\n",
        "    return score_classifier(pipe, X, y)[0] - self.baseline\n",
        "\n",
        "  def get_baseline(self):\n",
        "    return self.baseline\n",
        "\n",
        "evaluator = Evaluator()\n",
        "evaluator.fit(pipe, X_baseline, y_baseline)\n",
        "\n",
        "print(\"The baseline cross-validation score is: %f\" % \n",
        "      evaluator.get_baseline()) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The baseline cross-validation score is: 1248912305.301590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky1RbuALvBwC"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Based on the results of the EDA, we must perform the following steps for all models\n",
        "\n",
        "- **[ENG]** - Construct the initial model using `GrLivArea`, `OverallQual`,`GarageArea`, `1stFlrSF`, `YearBuilt` all as predictors.\n",
        "- **[ENG]** - Change `MSSubClass` into a categorical feature. \n",
        "- **[ENG]** - Replace \"NA\" with \"Absent\" for some of the features.\n",
        "\n",
        "- **[ENG]** - Discard `GarageYrBlt`. There is no reasonable imputation value and it is correlated with `YearBuilt`, so the information is redundant.\n",
        "- **[ENG]** - Impute `LotFrontage` to 0, median, or mean. \n",
        "- **[ENG]** - Impute `Electrical` to be the most frequent value.\n",
        "- **[ENG]** - Try: (1) impute MasVnrArea using the median/mean and MasVnrType with the most frequent observation, (2) first impute MasVnrType with the most frequent observation, then impute MasVnrArea with the average MasVnrArea for the most frequent MasVnrType.\n",
        "- **[ENG]** - Drop the record where `Stone` has 0 `MasVnrArea` (id 1242). This might be erroneous record.\n",
        "\n",
        "We will perform the following steps primarily for linear regression. Although, we may experiment with using these steps for other models. \n",
        "\n",
        "- **[ENG]** - Fit to the logarithm of `SalePrice` to satisfy linearity.\n",
        "- **[ENG]** - Discard `GarageYrBlt`\n",
        "- **[ENG]** - Discard `TotRmsAbvGrd`\n",
        "- **[ENG]** - Discard `TotalBsmtSF`\n",
        "- **[ENG]** - Discard `GarageCars`\n",
        "- **[ENG]** - Discard `2ndFlrSF`\n",
        "\n",
        "We can try the following additional steps on the models, especially linear regression, to see if it improves performance. \n",
        "\n",
        "- **[ENG]** - Drop `SalePrice` outliers to see if that improves model performance.\n",
        "- **[ENG]** - Try discarding `BsmtFullBath`\n",
        "- **[ENG]** - Try discarding `TotRmsAbvGrd` and keeping the individual above-grade room counts. Compare this to just keeping `TotRmsAbvGrd `to determine if there is any performance boost.\n",
        "- **[ENG]** - Try discarding `GrLivArea` or `1stFlrSF` or keeping both to see if there is any performance boost.\n",
        "- **[ENG]** - Try discarding `HalfBath`. If we are preprocessing in an alternate way, where we discard `2ndFlrSF`, then try to keep `HalfBath`\n",
        "- **[ENG]** - Try discarding either `BsmtUnfSF` or `BsmtFinSF1` or keeping both.\n",
        "- **[ENG]** - Try discarding `BedroomAbvGr` over `GrLivArea`\n",
        "- **[ENG]** - Consider dropping `FullBath` and `OverallQual`, which are correlated with `GrLivArea`. Note that `FullBath` is correlated with `OverallQual`\n",
        "- **[ENG]** - Run experiments using `FullBath`, `YearRemodAdd` as features\n",
        "- **[ENG]** - Run experiments using `MasVnrArea`, `Fireplaces`, `BsmtFinSF1`, `LotFrontage`, `2ndFlrSF`, `OpenPorchSF`, `WoodDeckSF` as features.\n",
        "- **[ENG]** - Run experiments using features with absolute correlation $<=0.30$ as predictors.\n",
        "\n",
        "If additional boosts in performance are necessary, then we might consider adding the categorical features. These features are somewhat undesirable  for linear regression, because they are not continuous features which would \"play\" better with the model. These might be useful in other models, however. \n",
        "\n",
        "- **[ENG]** - Empirically check if discarding `Neighborhood` or `MSZoning` improves performance\n",
        "- **[ENG]** - Discard `BsmtCond` or `BsmtQual`, depending on which has less correlation with `SalePrice`\n",
        "- **[ENG]** - Try discarding `BsmtExposure`, `BsmtFinType1`, and `BsmtFinType2`, as they are nominal variables, whereas `BsmtQual` and `BsmtCond` are continuous variables that capture some of the information. \n",
        "- **[ENG]** - Empirically check if discarding `GarageFinish` and/or `GarageType` in favour of `GarageQual` leads to performance boosts.\n",
        "- **[ENG]** - Try manipulating the basement and garage categorical variables to remove redundancy and improve performance. Create a preprocessor that empirically checks every non-empty subset of the collinear features, then tests to see which one yields the best performance. \n",
        "\n",
        "Some additional suggestions for experiments:\n",
        "\n",
        "- **[ENG]** - Try computing the number of years in-between YearBuilt and YearSold as a feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "MWravkh3vClg",
        "outputId": "47ed0b0d-812f-421f-b41e-4cf14a95d245"
      },
      "source": [
        "# Correcting columns that use 'NA' to denote a certain category of information\n",
        "cols_with_NA_category = ['Alley', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
        "                         'BsmtFinType2', 'BsmtQual', 'Fence', 'FireplaceQu', \n",
        "                         'GarageCond', 'GarageFinish', 'GarageQual', \n",
        "                         'GarageType', 'MiscFeature', 'PoolQC']\n",
        "NA_category = 'Absent'\n",
        "\n",
        "# Replace 'NA' with \"Absent\" to ensure the category is interpreted properly\n",
        "X['MSSubClass'] = X['MSSubClass'].astype('object')\n",
        "X[cols_with_NA_category] = X[cols_with_NA_category].fillna(NA_category)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Absent</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Absent</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Absent</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>62.0</td>\n",
              "      <td>7917</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Gilbert</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1999</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>953</td>\n",
              "      <td>953</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>953</td>\n",
              "      <td>694</td>\n",
              "      <td>0</td>\n",
              "      <td>1647</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>85.0</td>\n",
              "      <td>13175</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NWAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1978</td>\n",
              "      <td>1988</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>Stone</td>\n",
              "      <td>119.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>790</td>\n",
              "      <td>Rec</td>\n",
              "      <td>163</td>\n",
              "      <td>589</td>\n",
              "      <td>1542</td>\n",
              "      <td>GasA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>2073</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2073</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>7</td>\n",
              "      <td>Min1</td>\n",
              "      <td>2</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1978.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>2</td>\n",
              "      <td>500</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>Absent</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>66.0</td>\n",
              "      <td>9042</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1941</td>\n",
              "      <td>2006</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>CemntBd</td>\n",
              "      <td>CmentBd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Stone</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>275</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>877</td>\n",
              "      <td>1152</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1188</td>\n",
              "      <td>1152</td>\n",
              "      <td>0</td>\n",
              "      <td>2340</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>2</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1941.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>1</td>\n",
              "      <td>252</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>GdPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>2500</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>9717</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1950</td>\n",
              "      <td>1996</td>\n",
              "      <td>Hip</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>49</td>\n",
              "      <td>Rec</td>\n",
              "      <td>1029</td>\n",
              "      <td>0</td>\n",
              "      <td>1078</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>FuseA</td>\n",
              "      <td>1078</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1078</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>5</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>366</td>\n",
              "      <td>0</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9937</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Edwards</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1965</td>\n",
              "      <td>1965</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>BLQ</td>\n",
              "      <td>830</td>\n",
              "      <td>LwQ</td>\n",
              "      <td>290</td>\n",
              "      <td>136</td>\n",
              "      <td>1256</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1256</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1256</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1965.0</td>\n",
              "      <td>Fin</td>\n",
              "      <td>1</td>\n",
              "      <td>276</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>736</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>Absent</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows × 79 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     MSSubClass MSZoning  LotFrontage  ...  YrSold SaleType SaleCondition\n",
              "Id                                     ...                               \n",
              "1            60       RL         65.0  ...    2008       WD        Normal\n",
              "2            20       RL         80.0  ...    2007       WD        Normal\n",
              "3            60       RL         68.0  ...    2008       WD        Normal\n",
              "4            70       RL         60.0  ...    2006       WD       Abnorml\n",
              "5            60       RL         84.0  ...    2008       WD        Normal\n",
              "...         ...      ...          ...  ...     ...      ...           ...\n",
              "1456         60       RL         62.0  ...    2007       WD        Normal\n",
              "1457         20       RL         85.0  ...    2010       WD        Normal\n",
              "1458         70       RL         66.0  ...    2010       WD        Normal\n",
              "1459         20       RL         68.0  ...    2010       WD        Normal\n",
              "1460         20       RL         75.0  ...    2008       WD        Normal\n",
              "\n",
              "[1460 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0h3hq5MvLd_"
      },
      "source": [
        "# Compute the numerical and object columns\n",
        "mask = X.dtypes == 'object'\n",
        "object_cols = list(mask[mask].index)\n",
        "numerical_cols = list(set(X.columns) - set(object_cols))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIlP5GvXPTOO"
      },
      "source": [
        "ordinal_cols = ['LandSlope', 'ExterQual', 'ExterCond', 'BsmtQual', \n",
        "                'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', \n",
        "                'HeatingQC', 'KitchenQual', 'Functional', 'FireplaceQu', \n",
        "                'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', \n",
        "                'PoolQC', 'Fence', 'MiscFeature']\n",
        "\n",
        "nominal_cols = list(set(object_cols) - set(ordinal_cols))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0k45ho9Rt8t"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKkyOkUJPrOx"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
        "\n",
        "class FeatureSelection(BaseEstimator, TransformerMixin):\n",
        "  ''' Add this to a pipeline to ensure that only a `subset` of the features\n",
        "      is being used. Avoids having to pollute the global namespace with\n",
        "      modified copies of `X` with names like `X1`, `X2`, `X3`. Instead, just\n",
        "      pass in `X`, `y` without touching the features and let this transformer\n",
        "      handle the rest.\n",
        "  '''\n",
        "\n",
        "  def __init__(self, subset):\n",
        "    self.subset = subset\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y = None):\n",
        "    return X[self.subset]\n",
        "\n",
        "\n",
        "def transform(y):\n",
        "  return np.log(y)\n",
        "\n",
        "def inverse_transform(y):\n",
        "  return np.exp(y)\n",
        "\n",
        "def evaluate(evaluator, make_pipeline, prev_best_score):\n",
        "  cur_score = evaluator.evaluate(make_pipeline(), X, y)\n",
        "  print(\"The difference in performance is: %f\" % cur_score)\n",
        "  print(\"Change since last best score: %f\" % (cur_score - prev_best_score))\n",
        "  return cur_score\n",
        "\n",
        "def fit_best_features(make_pipeline, grid, evaluator, base_score):\n",
        "  best_score = None\n",
        "  best_feats = None \n",
        "  for key, cols in grid.items():\n",
        "    pipe = make_pipeline(cols)\n",
        "    score = evaluator.evaluate(pipe, X, y)\n",
        "\n",
        "    if best_score is None or score < best_score:\n",
        "      best_score = score\n",
        "      best_feats = key\n",
        "\n",
        "    print(key)\n",
        "    print(\"The difference in performance is: %f\" % score)\n",
        "    print(\"Change since last best score: %f\" % (score - base_score))\n",
        "    print()\n",
        "\n",
        "  print(\"The best performance increase is: %f\" % best_score)\n",
        "  print(\"The features that created this increase is: %s\" % best_feats)\n",
        "\n",
        "  return best_score, best_feats\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=global_valid_size, random_state=global_random_state\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm3MFfZTu9c9"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFDeuLuav-LZ"
      },
      "source": [
        "### Simple Model\n",
        "We begin by using only the most correlated features and seeing the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1jj0goAv7Qw"
      },
      "source": [
        "# Begin with the predictors that have the highest correlation with `SalePrice`\n",
        "predictors1 = ['GrLivArea', 'OverallQual', 'GarageArea', '1stFlrSF', 'YearBuilt']\n",
        "\n",
        "def make_pipeline1():\n",
        "  return Pipeline(steps=[('feature_selection', FeatureSelection(predictors1)),\n",
        "                         ('scale', StandardScaler()),\n",
        "                         ('model', LinearRegression())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvGkddE1xEnp"
      },
      "source": [
        "pretty_learning_curve(make_pipeline1(), X, y, \n",
        "                      scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=train_sizes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82beWI7kwC1v"
      },
      "source": [
        "score1 = evaluator.evaluate(make_pipeline1(), X, y)\n",
        "print(\"The difference in performance is: %f\" % score1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlbx448PwDqp"
      },
      "source": [
        "The number `282424869.901296` is interpreted as `current_score - baseline_score`\n",
        "\n",
        "We can see that with only 5 features, the linear regression model performs considerably worse than the baseline. Let consider adding additional predictors to see if that improves, performance. We prioritize adding the columns with highest correlation with `SalePrice`, but with no multicollinearity when paired with the existing columns in `predictors1` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZH3swp-wg1W"
      },
      "source": [
        "### With Multicollinearity\n",
        "Let us use `GarageCars` to observe what happens when we add a column that has multicollineariy (and thus, would violate one of linear regression's assumptions).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbL8lK8UwDPN"
      },
      "source": [
        "predictors2 = predictors1 + ['GarageCars']\n",
        "\n",
        "def make_pipeline2():\n",
        "  return Pipeline(steps=[('feature_selection', FeatureSelection(predictors2)),\n",
        "                         ('scale', StandardScaler()),\n",
        "                         ('model', LinearRegression())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmF-rZKZ0Rvx"
      },
      "source": [
        "pretty_learning_curve(make_pipeline2(), X, y, \n",
        "                      scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=train_sizes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEYYI8WByJKS"
      },
      "source": [
        "score2 = evaluator.evaluate(make_pipeline2(), X, y)\n",
        "print(\"The difference in performance is: %f\" % score2)\n",
        "print(\"Change since last best score: %f\" % (score2 - score1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfInhi8zyQsp"
      },
      "source": [
        "Observe how the resulting performance for `pipe2` is worse than `pipe1`. This might be explained by the fact that `GarageCars` is highly correlated with `GarageArea`, as shown by EDA.\n",
        "\n",
        "We instead add `LotFrontage`, which is only mildly correlated with features like `GarageArea`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVWM3cfXy5KX"
      },
      "source": [
        "predictors3 = predictors1 + ['LotFrontage']\n",
        "# predictors3 = predictors1 + ['OpenPorchSF'] # similarly does not improve performance\n",
        "\n",
        "def make_pipeline3():\n",
        "  numerical_imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "  imputer = ColumnTransformer(\n",
        "      transformers=[\n",
        "        ('num', numerical_imputer, predictors3)\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  return Pipeline(steps=[('feature_selection', FeatureSelection(predictors3)),\n",
        "                         ('imputer', imputer),\n",
        "                         ('scale', StandardScaler()),\n",
        "                         ('model', LinearRegression())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr1ahbME0Uxn"
      },
      "source": [
        "pretty_learning_curve(make_pipeline3(), X, y, \n",
        "                      scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=train_sizes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euaRGhADzDho"
      },
      "source": [
        "score3 = evaluator.evaluate(make_pipeline3(), X, y)\n",
        "print(\"The difference in performance is: %f\" % score3)\n",
        "print(\"Change since last best score: %f\" % (score3 - score1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H--Mr55szHIp"
      },
      "source": [
        "The resulting model has an even worse performance than the model which included `GarageCars`. The `LotFrontage` does not have any strong correlations with any other feature in `predictors1`. This suggests that the magnitude of correlation is somewhat unreliable as way to perform feature selection.\n",
        "\n",
        "Let us start with all of the features and see if removing features will improve performance, instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WpKfupQ0dFY"
      },
      "source": [
        "### All Numeric Features\n",
        "\n",
        "Here we add numeric features in an attempt to make the regression model achieve higher performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMP41PoQ20R2"
      },
      "source": [
        "def make_pipeline4():\n",
        "  predictors = numerical_cols\n",
        "\n",
        "  numerical_imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "  imputer = ColumnTransformer(\n",
        "      transformers=[\n",
        "        ('num', numerical_imputer, numerical_cols)\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  return Pipeline(steps=[('feature_selection', FeatureSelection(predictors)),\n",
        "                          ('imputer', imputer),\n",
        "                          ('scale', StandardScaler()),\n",
        "                          ('model', LinearRegression())])\n",
        "  \n",
        "pipe4 = make_pipeline4()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy_hwrXG87C1"
      },
      "source": [
        "pretty_learning_curve(make_pipeline4(), X, y, \n",
        "                      scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=[600, 700, 800, 900, 1000]) # Valid score spikes for size 200-500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eleh4d_621et"
      },
      "source": [
        "score4 = evaluator.evaluate(pipe4, X, y)\n",
        "print(\"The difference in performance is: %f\" % score4)\n",
        "print(\"Change since last best score: %f\" % (score4 - score1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak8_OwCe25BQ"
      },
      "source": [
        "By adding all of the numeric features, the linear regression model's performance is now better than the first model that was used. It seems that simply adding more information can improve model performance, so we can try again with the ordinal features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZMN5AxF2_Mx"
      },
      "source": [
        "### Adding Ordinal Features\n",
        "\n",
        "Here we add ordinal features to the model to improve model performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6QDBtqs3CmN"
      },
      "source": [
        "def get_trimmed(to_filter):\n",
        "  return list(set(ordinal_cols) - set(to_filter))\n",
        "\n",
        "def get_extended(to_add):\n",
        "  return ['LandSlope', 'ExterQual', 'BsmtQual', 'KitchenQual', 'FireplaceQu', 'GarageFinish'] + to_add\n",
        "\n",
        "# Uncomment to see the other results \n",
        "ordinal_cols_subsets = {\n",
        "    # 'landSlope' : ['LandSlope'],\n",
        "    # 'exterQual' : ['ExterQual'],\n",
        "    # 'exterCond' : ['ExterCond'],\n",
        "    # 'bsmtQual' : ['BsmtQual'],\n",
        "    # 'bsmtCond' : ['BsmtCond'],\n",
        "    # 'bsmtExposure' : ['BsmtExposure'],\n",
        "    # 'bsmtFinType1' : ['BsmtFinType1'],\n",
        "    # 'bsmtFinType2' : ['BsmtFinType2'],\n",
        "    # 'heatingQC' : ['HeatingQC'],\n",
        "    # 'kitchenQual' : ['KitchenQual'],\n",
        "    # 'functional' : ['Functional'],\n",
        "    # 'fireplaceQu' : ['FireplaceQu'],\n",
        "    # 'garageFinish' : ['GarageFinish'],\n",
        "    # 'garageQual' : ['GarageQual'],\n",
        "    # 'garageCond' : ['GarageCond'],\n",
        "    # 'pavedDrive' : ['PavedDrive'],\n",
        "    # 'poolQC' : ['PoolQC'],\n",
        "    # 'fence' : ['Fence'],\n",
        "    # 'miscFeature' : ['MiscFeature'],\n",
        "    # 'improve1' : ['LandSlope', 'ExterQual'],\n",
        "    # 'improve2' : ['LandSlope', 'ExterQual', 'BsmtQual'],\n",
        "    # 'improve3' : ['LandSlope', 'ExterQual', 'BsmtQual', 'KitchenQual'],\n",
        "    # 'improve4' : ['LandSlope', 'ExterQual', 'BsmtQual', 'KitchenQual', 'FireplaceQu'],\n",
        "    # 'improve5' : ['LandSlope', 'ExterQual', 'BsmtQual', 'KitchenQual', 'FireplaceQu', 'GarageFinish'],\n",
        "    # 'degrade1' : get_extended(['ExterCond']),\n",
        "    # 'degrade2' : get_extended(['BsmtCond']),\n",
        "    # 'degrade3' : get_extended(['BsmtExposure']),\n",
        "    # 'degrade4' : get_extended(['BsmtFinType1']),\n",
        "    # 'degrade5' : get_extended(['BsmtFinType2']),\n",
        "    # 'degrade6' : get_extended(['HeatingQC']),\n",
        "    # 'degrade7' : get_extended(['Functional']),\n",
        "    # 'degrade8' : get_extended(['GarageQual']),\n",
        "    # 'degrade9' : get_extended(['GarageCond']),\n",
        "    # 'degrade11' : get_extended(['PoolQC']),\n",
        "    # 'degrade12' : get_extended(['Fence']),\n",
        "    # 'degrade13' : get_extended(['MiscFeature']),\n",
        "    'degrade10' : get_extended(['PavedDrive']),\n",
        "    'extend1' : get_extended(['PavedDrive', 'ExterCond']),\n",
        "    'extend2' : get_extended(['PavedDrive', 'BsmtCond']),\n",
        "    'extend3' : get_extended(['PavedDrive', 'BsmtExposure']),\n",
        "    'extend4' : get_extended(['PavedDrive', 'BsmtFinType1']),\n",
        "    'extend5' : get_extended(['PavedDrive', 'BsmtFinType2']),\n",
        "    'extend6' : get_extended(['PavedDrive', 'HeatingQC']),\n",
        "    'extend7' : get_extended(['PavedDrive', 'Functional']),\n",
        "    'extend8' : get_extended(['PavedDrive', 'GarageQual']),\n",
        "    'extend9' : get_extended(['PavedDrive', 'GarageCond']),\n",
        "    'extend11' : get_extended(['PavedDrive', 'PoolQC']),\n",
        "    'extend12' : get_extended(['PavedDrive', 'Fence']),\n",
        "    'extend13' : get_extended(['PavedDrive', 'MiscFeature']),\n",
        "    # 'all' : get_trimmed([]),\n",
        "    # 'trim_1' : get_trimmed(['FireplaceQu']),\n",
        "    # 'trim_2' : get_trimmed(['PoolQC']),\n",
        "    # 'trim_3' : get_trimmed(['MiscFeature']),\n",
        "    # 'trim_4' : get_trimmed(['Fence']),\n",
        "    # 'trim_5' : get_trimmed(['Fence', 'FireplaceQu', 'PoolQC', 'MiscFeature']),\n",
        "}\n",
        "\n",
        "def make_pipeline5(numerical_cols, ordinal_cols):\n",
        "\n",
        "  predictors = numerical_cols + ordinal_cols\n",
        "\n",
        "  numerical_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='mean')),\n",
        "    ('scale', StandardScaler())\n",
        "  ])\n",
        "\n",
        "  ordinal_transformer = Pipeline(steps=[\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('ord', ordinal_transformer, ordinal_cols)\n",
        "      ])\n",
        "\n",
        "  return Pipeline(steps=[('feature_selection', FeatureSelection(predictors)),\n",
        "                         ('preprocess', preprocessor),\n",
        "                         ('model', LinearRegression())])\n",
        "\n",
        "def make_pipeline5_with_ord(ord_cols):\n",
        "    return make_pipeline5(numerical_cols, ord_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sND4VOyq3Dyh"
      },
      "source": [
        "best_score5, best_ord_feats5 = fit_best_features(make_pipeline5_with_ord,\n",
        "                                               ordinal_cols_subsets,\n",
        "                                               evaluator, score4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55SWnjjP3FpA"
      },
      "source": [
        "The following is observed:\n",
        "- `OverallQual`, `Fence`, `FireplaceQu`, `PoolQC`, `MiscFeatures` - These features appear to be useless or actively detrimental to the linear regression model if they are the sole feature being added. In particular, `OverallQual` pushes the MSE of the linear regression to infinity when it is added, so we are forced to discard this feature. \n",
        "- `ExterQual`, `GarageQual` - Leads to a performance increase. \n",
        "\n",
        "One hypothesis for why some features cause performance degradation is that the linear regression model does not behave well when the categorical variable is 90-99% of one category. The intuition is that such features wouldn't be informative anyways, because all but one category have insufficient data points and you cannot generalize from a small sample size reliably. \n",
        "\n",
        "The following features, when added to the numerical columns, leads to a performance increase:\n",
        "- `LandSlope` - Skewed class \n",
        "- `ExterQual` - Two comparable classes\n",
        "- `BsmtQual` - Two comparable classes\n",
        "- `KitchenQual` - Two comparable classes \n",
        "- `FireplaceQu` - Three comparable classes \n",
        "- `GarageFinish` - Three comparable classes \n",
        "\n",
        "The following features, when added to the categorical columns, leads to performance degradation.\n",
        "- `ExterCond` - Extremely detrimental - Skewed class\n",
        "- `BsmtCond` - Skewed class \n",
        "- `BsmtExposure` - Skewed class\n",
        "- `BsmtFinType1` - At least two comparable classes \n",
        "- `BsmtFinType2` - Skewed class\n",
        "- `HeatingQC` - Extremely detrimental\n",
        "- `Functional` - Extremely detrimental - Skewed class\n",
        "- `GarageQual` - Extremely detrimental - Skewed class\n",
        "- `GarageCond`  - Extremely detrimental - Skewed class \n",
        "- `PavedDrive` - Skewed class \n",
        "- `PoolQC` - Extremely detrimental - Skewed class\n",
        "- `Fence` - Skewed class\n",
        "- `MiscFeature` - Skewed class\n",
        "\n",
        "This scheme is not perfect and there are counter-examples. For example, `LandSlope` is dominated by one category, but still provides a performance increase. Note, however, that the increase is relatively small compared to the other features: `-163187.196632`. On the other hand, `BsmtFinType1` is not dominated by one category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAmMOarB9YEN"
      },
      "source": [
        "pretty_learning_curve(make_pipeline5_with_ord(ordinal_cols_subsets[best_ord_feats5]), \n",
        "                      X, y, scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=[600, 700, 800, 900, 1000]) # Valid score spikes for size 200-500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pBlJxxr3JJe"
      },
      "source": [
        "### Adding Nominal Features\n",
        "\n",
        "Here we add nominal features to improve model performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgK44ny33Kjp"
      },
      "source": [
        "# Uncomment to see all outputs\n",
        "nominal_cols_subsets = {\n",
        "    'baseline' : [],\n",
        "    'all' : nominal_cols,\n",
        "    # 'Neighborhood' : ['Neighborhood'],\n",
        "    # 'Condition1' : ['Condition1'],\n",
        "    # 'GarageType' : ['GarageType'],\n",
        "    # 'HouseStyle' : ['HouseStyle'],\n",
        "    # 'Condition2' : ['Condition2'],\n",
        "    # 'Exterior1st' : ['Exterior1st'],\n",
        "    # 'BldgType' : ['BldgType'],\n",
        "    # 'CentralAir' : ['CentralAir'],\n",
        "    # 'Street' : ['Street'],\n",
        "    # 'MSSubClass' : ['MSSubClass'],\n",
        "    # 'Alley' : ['Alley'],\n",
        "    # 'MasVnrType' : ['MasVnrType'],\n",
        "    # 'Foundation' : ['Foundation'],\n",
        "    # 'MSZoning' : ['MSZoning'],\n",
        "    # 'LotConfig' : ['LotConfig'],\n",
        "    # 'Heating' : ['Heating'],\n",
        "    # 'SaleType' : ['SaleType'],\n",
        "    # 'RoofStyle' : ['RoofStyle'],\n",
        "    # 'RoofMatl' : ['RoofMatl'],\n",
        "    # 'LandContour' : ['LandContour'],\n",
        "    # 'LotShape' : ['LotShape'],\n",
        "    # 'Exterior2nd' : ['Exterior2nd'],\n",
        "    # 'SaleCondition' : ['SaleCondition'],\n",
        "    # 'Utilities' : ['Utilities'],\n",
        "    # 'Electrical' : ['Electrical'],\n",
        "    'cherry-pick' : ['Condition1', 'HouseStyle', 'BldgType', 'Street',\n",
        "                     'MSSubClass', 'Alley', 'MasVnrType', 'MSZoning',\n",
        "                     'LotConfig', 'LandContour'],\n",
        "    'highest-decrease' : ['HouseStyle', 'BldgType', 'MSSubClass', 'MSZoning'],\n",
        "    'cherry-pick-2' : ['HouseStyle', 'MSZoning'],\n",
        "}\n",
        "\n",
        "def make_pipeline6(numerical_cols, ordinal_cols, nominal_cols):\n",
        "\n",
        "  predictors = numerical_cols + ordinal_cols + nominal_cols\n",
        "\n",
        "  numerical_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='mean')),\n",
        "    ('scale', StandardScaler())\n",
        "  ])\n",
        "\n",
        "  ordinal_transformer = Pipeline(steps=[\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  nominal_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('ord', ordinal_transformer, ordinal_cols),\n",
        "        ('nom', nominal_transformer, nominal_cols)\n",
        "      ])\n",
        "\n",
        "  return Pipeline(steps=[('feature_selection', FeatureSelection(predictors)),\n",
        "                         ('preprocess', preprocessor),\n",
        "                         ('model', LinearRegression())])\n",
        "\n",
        "def make_pipeline6_with_nom(nominal_cols):\n",
        "    return make_pipeline6(numerical_cols, ordinal_cols_subsets[best_ord_feats5],\n",
        "                          nominal_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUeiLX8C7KDd"
      },
      "source": [
        "score6, best_nom_feats6 = fit_best_features(make_pipeline6_with_nom,\n",
        "                                            nominal_cols_subsets,\n",
        "                                            evaluator, best_score5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVjhA8_p8ZP_"
      },
      "source": [
        "pretty_learning_curve(make_pipeline6_with_nom(nominal_cols_subsets[best_nom_feats6]), \n",
        "                      X, y, \n",
        "                      scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=[400, 500, 600, 700, 800, 900, 1000, 1100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3VDC_-u4fy3"
      },
      "source": [
        "### Transforming the Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYc6hHI13NIL"
      },
      "source": [
        "def make_pipeline7(numerical_cols, ordinal_cols, nominal_cols):\n",
        "  predictors = numerical_cols + ordinal_cols + nominal_cols\n",
        "\n",
        "  numerical_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='mean')),\n",
        "    ('scale', StandardScaler())\n",
        "  ])\n",
        "\n",
        "  ordinal_transformer = Pipeline(steps=[\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  nominal_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('ord', ordinal_transformer, ordinal_cols),\n",
        "        ('nom', nominal_transformer, nominal_cols)\n",
        "      ])\n",
        "\n",
        "  pipe = Pipeline(steps=[('feature_selection', FeatureSelection(predictors)),\n",
        "                         ('preprocess', preprocessor),\n",
        "                         ('model', LinearRegression())])\n",
        "  \n",
        "  return TransformedTargetRegressor(regressor=pipe,\n",
        "                                    func=transform,\n",
        "                                    inverse_func=inverse_transform)\n",
        "\n",
        "pipe7 = make_pipeline7(numerical_cols,\n",
        "                       ordinal_cols_subsets[best_ord_feats5],\n",
        "                       nominal_cols_subsets[best_nom_feats6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wjetBCi4Xt5"
      },
      "source": [
        "score7 = evaluator.evaluate(pipe7, X, y)\n",
        "print(\"The difference in performance is: %f\" % score7)\n",
        "print(\"Change since last best score: %f\" % (score7 - score6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmNEmhmrDhWK"
      },
      "source": [
        "By applying a logarithm onto the target feature, we able to fit all of the features onto the `LinearRegression` model. Although this does not lead to a performance improvement in the cross-validation score, it opens the possibility to fit all of the features, whereas before the score became too large to measure. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhmMsfNRAKtL"
      },
      "source": [
        "## Linear Regression II\n",
        "\n",
        "It may be more effective to transform the target, then attempt to fit the linear regression model on all of the features. This would allow us to see how removing or adding features affects the model score, while accounting for all of the interactions between features, whether they are good or bad. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWNnGCep_LrL"
      },
      "source": [
        "### All Features (Again)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hML9uGYZ_OtP"
      },
      "source": [
        "def make_pipeline1a(numerical_cols, ordinal_cols, nominal_cols):\n",
        "  predictors = numerical_cols + ordinal_cols + nominal_cols\n",
        "\n",
        "  numerical_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='mean')),\n",
        "    ('scale', StandardScaler())\n",
        "  ])\n",
        "\n",
        "  ordinal_transformer = Pipeline(steps=[\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  nominal_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('ord', ordinal_transformer, ordinal_cols),\n",
        "        ('nom', nominal_transformer, nominal_cols)\n",
        "      ])\n",
        "\n",
        "  pipe = Pipeline(steps=[('feature_selection', FeatureSelection(predictors)),\n",
        "                         ('preprocess', preprocessor),\n",
        "                         ('model', LinearRegression())])\n",
        "  \n",
        "  return TransformedTargetRegressor(regressor=pipe,\n",
        "                                    func=transform,\n",
        "                                    inverse_func=inverse_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kd4yUJSCRPo"
      },
      "source": [
        "pretty_learning_curve(make_pipeline1a(numerical_cols, ordinal_cols, nominal_cols), \n",
        "                      X, y, \n",
        "                      scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=[100 * i for i in range(5, 12)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekjwGneM_RRl"
      },
      "source": [
        "score1a = evaluate(evaluator, \n",
        "                   lambda: make_pipeline1a(numerical_cols,\n",
        "                                           ordinal_cols,\n",
        "                                           nominal_cols), \n",
        "                   score6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBdyL06yDpNG"
      },
      "source": [
        "While the performance appears to be worse than `score6`, the best score we obtained from our first attempt to fit linear regression, one thing to observe is that the best training score for our first attempt is: `448352332.715567`. \n",
        "In contrast, the training score here is `283302039.440293`.\n",
        "\n",
        "We could try tuning hyperparameters to see if we can narrow the gap between training and cross-validation for our current model, then it might beat our previous best. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noE7pfkaEWpV"
      },
      "source": [
        "### Ridge Regression\n",
        "\n",
        "We will attempt to put an L2 regularization term to the `LinearRegression` model using `RidgeRegression`. Ideally, this will minimize overfitting and allow us to beat our previously best scoring model. Even more ideal is if this technique allows us to beat the baseline. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i23G-UclEZD1"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "def make_pipeline2a(numerical_cols, ordinal_cols, nominal_cols, alpha=1.0):\n",
        "  predictors = numerical_cols + ordinal_cols + nominal_cols\n",
        "\n",
        "  numerical_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='mean')),\n",
        "    ('scale', StandardScaler())\n",
        "  ])\n",
        "\n",
        "  ordinal_transformer = Pipeline(steps=[\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  nominal_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('ord', ordinal_transformer, ordinal_cols),\n",
        "        ('nom', nominal_transformer, nominal_cols)\n",
        "      ])\n",
        "\n",
        "  pipe = Pipeline(steps=[('feature_selection', FeatureSelection(predictors)),\n",
        "                         ('preprocess', preprocessor),\n",
        "                         ('model', Ridge(alpha=alpha))])\n",
        "  \n",
        "  return TransformedTargetRegressor(regressor=pipe,\n",
        "                                    func=transform,\n",
        "                                    inverse_func=inverse_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUM0xrHWFdB-"
      },
      "source": [
        "alphas = [1, 10, 100, 1000, 10000, 11000, 15000, 18000, 20000, 30000]\n",
        "scores = []\n",
        "\n",
        "score2a = None\n",
        "best_alpha = None\n",
        "for alpha in alphas:\n",
        "  print(\"Alpha = %f\" % alpha)\n",
        "  score = evaluate(evaluator, \n",
        "                   lambda: make_pipeline2a(numerical_cols,\n",
        "                                           ordinal_cols,\n",
        "                                           nominal_cols,\n",
        "                                           alpha), \n",
        "                   score6)\n",
        "  \n",
        "  scores.append(score)\n",
        "\n",
        "  if score2a is None or score < score2a:\n",
        "    score2a = score\n",
        "    best_alpha = alpha\n",
        "\n",
        "plt.plot(alphas, scores)\n",
        "plt.title(\"Hyperparameter Tuning of Alpha\")\n",
        "plt.xlabel(\"Alpha\")\n",
        "plt.ylabel(\"Mean cross-validation score\")\n",
        "plt.tight_layout()\n",
        "\n",
        "print(\"The best score is: %f\" % score2a)\n",
        "print(\"The alpha setting is: %f\" % best_alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5N7TUE1JZyp"
      },
      "source": [
        "pretty_learning_curve(make_pipeline2a(numerical_cols, ordinal_cols, nominal_cols, best_alpha), \n",
        "                      X, y, \n",
        "                      scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=[100 * i for i in range(5, 12)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YyaHPxjJ_Vj"
      },
      "source": [
        "Unfortunately, ridge regression can only push down the cross-validation score to be `1607489203.257070` higher than our previous best score. As the learning curve above shows, we have already reduced overfitting to nearly the minimum possible degree.  \n",
        "\n",
        "The model appears to be severely underfitting, as both the training and validation score are significantly worse than the previous linear regression model we used. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoVcYnoALfDD"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "def make_pipeline3a(numerical_cols, ordinal_cols, nominal_cols, alpha=1.0):\n",
        "  predictors = numerical_cols + ordinal_cols + nominal_cols\n",
        "\n",
        "  numerical_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='mean')),\n",
        "    ('scale', StandardScaler())\n",
        "  ])\n",
        "\n",
        "  ordinal_transformer = Pipeline(steps=[\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  nominal_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('ord', ordinal_transformer, ordinal_cols),\n",
        "        ('nom', nominal_transformer, nominal_cols)\n",
        "      ])\n",
        "\n",
        "  pipe = Pipeline(steps=[('feature_selection', FeatureSelection(predictors)),\n",
        "                         ('preprocess', preprocessor),\n",
        "                         ('model', Lasso(alpha=alpha))])\n",
        "  \n",
        "  return TransformedTargetRegressor(regressor=pipe,\n",
        "                                    func=transform,\n",
        "                                    inverse_func=inverse_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-2G9cMNMpyk"
      },
      "source": [
        "### Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6FCUKq5Le3m"
      },
      "source": [
        "alphas = [0.001, 0.01, 0.1, 1, 10]\n",
        "scores = []\n",
        "\n",
        "score3a = None\n",
        "best_lasso_alpha = None\n",
        "for alpha in alphas:\n",
        "  print(\"Alpha = %f\" % alpha)\n",
        "  score = evaluate(evaluator, \n",
        "                   lambda: make_pipeline3a(numerical_cols,\n",
        "                                           ordinal_cols,\n",
        "                                           nominal_cols,\n",
        "                                           alpha), \n",
        "                   score6)\n",
        "  \n",
        "  scores.append(score)\n",
        "\n",
        "  if score3a is None or score < score3a:\n",
        "    score3a = score\n",
        "    best_lasso_alpha = alpha\n",
        "\n",
        "plt.plot(alphas, scores)\n",
        "plt.title(\"Hyperparameter Tuning of Alpha\")\n",
        "plt.xlabel(\"Alpha\")\n",
        "plt.ylabel(\"Mean cross-validation score\")\n",
        "plt.tight_layout()\n",
        "\n",
        "print(\"The best score is: %f\" % score3a)\n",
        "print(\"The alpha setting is: %f\" % best_lasso_alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GQWm356LukE"
      },
      "source": [
        "pretty_learning_curve(make_pipeline3a(numerical_cols, ordinal_cols, nominal_cols, best_lasso_alpha), \n",
        "                      X, y, \n",
        "                      scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=[100 * i for i in range(1, 12)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TwCRu4ENbMK"
      },
      "source": [
        "Lasso Regression appears to work better than Ridge Regression, since the training error is lower. The problem, however, is that the training error is still one order of magnitude higher than the training score achieved by the simple linear regression model incorporating all features.\n",
        "\n",
        "This model is significantly underfitting, we will attempt to use a more complex model like Random Forests or neural nets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx9jvdhiqrG0"
      },
      "source": [
        "### Rank Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uysYQ6f7qnji"
      },
      "source": [
        "### Discarding Highly Correlated Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg927807qzXO"
      },
      "source": [
        "### Discarding Features Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws6k6z-Zo73D"
      },
      "source": [
        "## Random Forest Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4gPydzDv9oJ"
      },
      "source": [
        "### Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXmiHbUHqMOH"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def make_pipeline1b(numerical_cols, ordinal_cols, nominal_cols,\n",
        "                    max_depth=10, n_estimators=200,\n",
        "                    min_samples_split=5, min_samples_leaf=2):\n",
        "  predictors = numerical_cols + ordinal_cols + nominal_cols\n",
        "\n",
        "  numerical_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='mean')),\n",
        "  ])\n",
        "\n",
        "  ordinal_transformer = Pipeline(steps=[\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  nominal_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('ord', ordinal_transformer, ordinal_cols),\n",
        "        ('nom', nominal_transformer, nominal_cols)\n",
        "      ])\n",
        "  \n",
        "  model = RandomForestRegressor(criterion=\"mse\", verbose=1, n_jobs=-1,\n",
        "                                max_depth=max_depth)\n",
        "\n",
        "  pipe = Pipeline(steps=[('feature_selection', FeatureSelection(predictors)),\n",
        "                         ('preprocess', preprocessor),\n",
        "                         ('model', model)])\n",
        "  \n",
        "  return TransformedTargetRegressor(regressor=pipe,\n",
        "                                    func=transform,\n",
        "                                    inverse_func=inverse_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202xX9nxrewo"
      },
      "source": [
        "pretty_learning_curve(make_pipeline1b(numerical_cols, ordinal_cols, nominal_cols), \n",
        "                      X, y, \n",
        "                      scoring=make_scorer(mean_squared_error), \n",
        "                      train_sizes=train_sizes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPhkA1JWruJA"
      },
      "source": [
        "score1b = evaluate(evaluator, \n",
        "                   lambda: make_pipeline1b(numerical_cols,\n",
        "                                           ordinal_cols,\n",
        "                                           nominal_cols), \n",
        "                   score6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbZlmsiouzVT"
      },
      "source": [
        "According to the learning curve, there appears to be some overfitting. However, the cross-validation score is far lower than the baseline linear regression model. \n",
        "\n",
        "Hence, the random forest regressor is a good starting point to obtain more accurate predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTUuzEH2tuLf"
      },
      "source": [
        "# # Uncomment for submission to Kaggle\n",
        "# submit_pipe = make_pipeline1b(numerical_cols,\n",
        "#                               ordinal_cols,\n",
        "#                               nominal_cols)\n",
        "# submit_pipe.fit(X, y)\n",
        "# rf_preds = submit_pipe.predict(X_test)\n",
        "\n",
        "# output = pd.DataFrame({'Id': X_test.index, 'SalePrice': rf_preds})\n",
        "# output.to_csv(workdir + '/rf-submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SkKzO1cv-9X"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4zd_N7jwCDR"
      },
      "source": [
        "# Number of decision trees\n",
        "n_estimators = [200, 300, 400, 500]\n",
        "\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [10, 20, 30, 40]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "random_grid = {'regressor__model__n_estimators': n_estimators,\n",
        "               'regressor__model__max_features': max_features,\n",
        "               'regressor__model__max_depth': max_depth,\n",
        "               'regressor__model__min_samples_split': min_samples_split,\n",
        "               'regressor__model__min_samples_leaf': min_samples_leaf,\n",
        "               'regressor__model__bootstrap': bootstrap}\n",
        "\n",
        "# Randomly sample the hyperparameters and determine the best combination.\n",
        "pipeline2b = RandomizedSearchCV(estimator =  make_pipeline1b(numerical_cols,\n",
        "                                                             ordinal_cols,\n",
        "                                                             nominal_cols), \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 20, cv = 10, verbose=2, \n",
        "                                random_state=42, n_jobs = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxZxWYKHxM3p"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=global_valid_size, random_state=global_random_state\n",
        ")\n",
        "\n",
        "pipeline2b.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsPg5rQPYK5y"
      },
      "source": [
        "best_random2b = pipeline2b.best_estimator_\n",
        "best_random2b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL21PbExYJEd"
      },
      "source": [
        "score2b = evaluator.evaluate(best_random2b, X, y)\n",
        "print(\"The difference in performance is: %f\" % score2b)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I9gn5ukkXiB"
      },
      "source": [
        "score1b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpuPUWufizTv"
      },
      "source": [
        "The resulting cross-validation score is a bit better than the default `RandomForestRegressor` settings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm8VQdoMjPqL"
      },
      "source": [
        "# # Uncomment for submission to Kaggle\n",
        "# best_random2b.fit(X, y)\n",
        "# rf_preds = best_random2b.predict(X_test)\n",
        "\n",
        "# output = pd.DataFrame({'Id': X_test.index, 'SalePrice': rf_preds})\n",
        "# output.to_csv(workdir + '/rf-submission2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltCxVLBYkzXO"
      },
      "source": [
        "Unfortunately, the actual results on the test dataset on Kaggle are actually slightly worse than the default settings, `0.14641` vs. `0.14684`. \n",
        "\n",
        "This suggests some overfitting to the cross-validation set, as opposed to a decrease in generalization error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTFc3Wk9o-Es"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv5olraSwClt"
      },
      "source": [
        "### Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62_nyeQuOxq3"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "def make_pipeline1c(numerical_cols, ordinal_cols, nominal_cols,\n",
        "                    max_depth=10, n_estimators=200, learning_rate=0.05):\n",
        "  predictors = numerical_cols + ordinal_cols + nominal_cols\n",
        "\n",
        "  numerical_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='mean')),\n",
        "  ])\n",
        "\n",
        "  ordinal_transformer = Pipeline(steps=[\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  nominal_transformer = Pipeline(steps=[\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoding', OneHotEncoder(handle_unknown='ignore'))\n",
        "  ])\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('ord', ordinal_transformer, ordinal_cols),\n",
        "        ('nom', nominal_transformer, nominal_cols)\n",
        "      ])\n",
        "  \n",
        "  model = XGBRegressor(criterion=\"mse\", verbose=1, n_jobs=-1,\n",
        "                       n_estimators=n_estimators, max_depth=max_depth,\n",
        "                       learning_rate=learning_rate,\n",
        "                       objective='reg:squarederror',\n",
        "                       random_state=global_random_state)\n",
        "\n",
        "  pipe = Pipeline(steps=[('feature_selection', FeatureSelection(predictors)),\n",
        "                         ('preprocess', preprocessor),\n",
        "                         ('model', model)])\n",
        "  \n",
        "  return TransformedTargetRegressor(regressor=pipe,\n",
        "                                    func=transform,\n",
        "                                    inverse_func=inverse_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnmI_VhfOy28"
      },
      "source": [
        "score1 = evaluator.evaluate(make_pipeline1c(numerical_cols, ordinal_cols, nominal_cols), \n",
        "                            X, y)\n",
        "print(\"The difference in performance is: %f\" % score1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNt-H5oNOz2O"
      },
      "source": [
        "# # Uncomment for submission to Kaggle\n",
        "# submit_pipe = make_pipeline1c(numerical_cols,\n",
        "#                               ordinal_cols,\n",
        "#                               nominal_cols)\n",
        "# submit_pipe.fit(X, y)\n",
        "# xg_preds = submit_pipe.predict(X_test)\n",
        "\n",
        "# output = pd.DataFrame({'Id': X_test.index, 'SalePrice': xg_preds})\n",
        "# output.to_csv(workdir + '/xg-submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i73f4rWgh0T8"
      },
      "source": [
        "This approach yields a fairly high score, moreso than `RandomForestRegressor`. We will perform hyperparameter tuning to get the most out of this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bprAuc5UwDq_"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS6elWFnhyKp"
      },
      "source": [
        "# Number of decision trees\n",
        "n_estimators = [200, 300, 400, 500]\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [10, 20, 30, 40]\n",
        "\n",
        "# Choice of booster\n",
        "boosters = ['gbtree', 'gblinear', 'dart']\n",
        "\n",
        "# Gamma\n",
        "gamma = [0, 0.1, 1, 10]\n",
        "\n",
        "# Max delta step\n",
        "max_delta_steps = [0, 0.1, 1, 10]\n",
        "\n",
        "# Minimum child weight\n",
        "min_child_weights = [1, 10, 100]\n",
        "\n",
        "# Regularization\n",
        "reg_alphas = [0, 1, 10, 100]\n",
        "reg_lambdas = [0, 1, 10, 100]\n",
        "\n",
        "random_grid = {'regressor__model__n_estimators': n_estimators,\n",
        "               'regressor__model__max_depth': max_depth,\n",
        "               'regressor__model__boosters' : boosters,\n",
        "               'regressor__model__gamma' : gamma,\n",
        "               'regressor__model__max_delta_step' : max_delta_steps,\n",
        "               'regressor__model__min_child_weight' : min_child_weights,\n",
        "               'regressor__model__reg_alpha' : reg_alphas,\n",
        "               'regressor__model__reg_lambda' : reg_lambdas,\n",
        "}\n",
        "\n",
        "# Randomly sample the hyperparameters and determine the best combination.\n",
        "pipeline2c = RandomizedSearchCV(estimator =  make_pipeline1c(numerical_cols,\n",
        "                                                             ordinal_cols,\n",
        "                                                             nominal_cols), \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 20, cv = 10, verbose=2, \n",
        "                                random_state=global_random_state, n_jobs = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz5N9z3ohzef"
      },
      "source": [
        "# Perform the random search\n",
        "pipeline2c.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjEFbEmRh_Po"
      },
      "source": [
        "best_random2c = pipeline2c.best_estimator_\n",
        "best_random2c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sJC3y4QiAiW"
      },
      "source": [
        "score2c = evaluator.evaluate(best_random2c, X, y)\n",
        "print(\"The difference in performance is: %f\" % score2c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we52q2pRiBSO"
      },
      "source": [
        "Unfortunately, the randomized grid search was unlucky and we did not find a result that was better than the default settings. We will try to use deterministic grid search in the range around the default settings and see if that optimizes the performance further. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEtRc49xiE4n"
      },
      "source": [
        "# Number of decision trees\n",
        "n_estimators = [170, 200, 220]\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [3, 5, 10]\n",
        "\n",
        "# # Gamma\n",
        "gamma = [0, 0.1]\n",
        "\n",
        "# # Max delta step\n",
        "max_delta_steps = [0, 0.1]\n",
        "\n",
        "# Minimum child weight\n",
        "min_child_weights = [1, 5]\n",
        "\n",
        "# Regularization\n",
        "reg_alphas = [0, 10]\n",
        "reg_lambdas = [0, 10]\n",
        "\n",
        "param_grid = {'regressor__model__n_estimators': n_estimators,\n",
        "               'regressor__model__max_depth': max_depth,\n",
        "               'regressor__model__boosters' : boosters,\n",
        "              #  'regressor__model__gamma' : gamma,\n",
        "              #  'regressor__model__max_delta_step' : max_delta_steps,\n",
        "               'regressor__model__min_child_weight' : min_child_weights,\n",
        "               'regressor__model__reg_alpha' : reg_alphas,\n",
        "               'regressor__model__reg_lambda' : reg_lambdas,\n",
        "}\n",
        "\n",
        "# Randomly sample the hyperparameters and determine the best combination.\n",
        "grid_search3c = GridSearchCV(estimator = make_pipeline1c(numerical_cols,\n",
        "                                                             ordinal_cols,\n",
        "                                                             nominal_cols), \n",
        "                             param_grid = param_grid, \n",
        "                             cv = 3, n_jobs = -1, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdg8Q6bJiHBu"
      },
      "source": [
        "# Perform the grid search\n",
        "grid_search3c.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGoPidXeiTcn"
      },
      "source": [
        "# Extract the best hyperparameter settings\n",
        "best_det3c = grid_search3c.best_estimator_\n",
        "best_det3c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5DO58t5iSRO"
      },
      "source": [
        "# Evaluating the resulting performance\n",
        "score3c = evaluator.evaluate(best_det3c, X, y)\n",
        "print(\"The difference in performance is: %f\" % score3c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlN9ZrjRilxS"
      },
      "source": [
        "We've successfully improved the performance of our XGBRegressor by just a little bit. This is the best model so far. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63DNTpwqiYEH"
      },
      "source": [
        "# # Uncomment for submission to Kaggle\n",
        "# best_det3c.fit(X, y)\n",
        "# xg_preds = best_det3c.predict(X_test)\n",
        "\n",
        "# output = pd.DataFrame({'Id': X_test.index, 'SalePrice': xg_preds})\n",
        "# output.to_csv(workdir + '/xg-submission2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5QaAunrkAsp"
      },
      "source": [
        "Unfortunately, the actual results on Kaggle are slightly below the default `XGBRegressor` settings. \n",
        "\n",
        "The best score was `~0.131` with the default `XGBRegressor` whereas the tuned model has a score of `~0.133`. A more complex model might be necessary to achieve better predictions.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMKErTcgMFFu"
      },
      "source": [
        "## Artificial Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_yZCM0AQpPA",
        "outputId": "cb3e77f6-5ff7-42d7-dab9-8acee94e6756"
      },
      "source": [
        "### Setup\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "\n",
        "# Basic imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow import data\n",
        "\n",
        "# TensorFlow Docs\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.modeling\n",
        "import tensorflow_docs.plots\n",
        "\n",
        "# Set up TensorBoard\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile\n",
        "\n",
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
        "shutil.rmtree(logdir, ignore_errors=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox4_2pSPsXwh"
      },
      "source": [
        "models = {}\n",
        "model_histories = {}\n",
        "model_evaluations = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdGOYepvnqhY"
      },
      "source": [
        "### Simple Model, Numerical Columns Only\n",
        "\n",
        "This section is just testing out artificial neural networks to see if they work for this regression problem.\n",
        "\n",
        "The \"first\" model in our ANN investigation will be the baseline model in the next section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF1CFCals5gG"
      },
      "source": [
        "simple_handle = 'simple'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaURrXWbsExr"
      },
      "source": [
        "#### Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jjPUrArq6hZ"
      },
      "source": [
        "# Dealing with missing values\n",
        "impute = SimpleImputer(strategy='mean')\n",
        "\n",
        "X_train_imputed = pd.DataFrame(impute.fit_transform(X_train[numerical_cols]), columns=numerical_cols)\n",
        "X_valid_imputed = pd.DataFrame(impute.transform(X_valid[numerical_cols]), columns=numerical_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNKk6PeusHtC"
      },
      "source": [
        "#### Normalizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9Ri9bCocnsEt",
        "outputId": "c0a4adc4-52d7-4028-b34f-bbcafb9657f0"
      },
      "source": [
        "# Normalizing the data\n",
        "def build_normalizer(X):\n",
        "  normalizer = preprocessing.Normalization(input_shape=[X.shape[1],])\n",
        "  normalizer.adapt(np.array(X))\n",
        "  return normalizer\n",
        "\n",
        "X_train_imputed.describe().transpose()[['mean', 'std']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>OverallQual</th>\n",
              "      <td>6.079256</td>\n",
              "      <td>1.357888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <td>94.852250</td>\n",
              "      <td>128.397120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fireplaces</th>\n",
              "      <td>0.612524</td>\n",
              "      <td>0.635668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MiscVal</th>\n",
              "      <td>55.864971</td>\n",
              "      <td>587.302105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GrLivArea</th>\n",
              "      <td>1522.137965</td>\n",
              "      <td>517.810449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotFrontage</th>\n",
              "      <td>69.668667</td>\n",
              "      <td>20.832633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PoolArea</th>\n",
              "      <td>1.786693</td>\n",
              "      <td>33.345922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <td>23.607632</td>\n",
              "      <td>64.275741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3SsnPorch</th>\n",
              "      <td>3.325832</td>\n",
              "      <td>28.732385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1stFlrSF</th>\n",
              "      <td>1161.722114</td>\n",
              "      <td>373.986135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <td>354.725049</td>\n",
              "      <td>440.838061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <td>1055.343444</td>\n",
              "      <td>410.235424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MasVnrArea</th>\n",
              "      <td>103.553589</td>\n",
              "      <td>181.168466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <td>0.418787</td>\n",
              "      <td>0.514966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotArea</th>\n",
              "      <td>10567.966732</td>\n",
              "      <td>10291.276619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <td>565.992172</td>\n",
              "      <td>433.040509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <td>1978.012397</td>\n",
              "      <td>24.316390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <td>47.378669</td>\n",
              "      <td>67.628982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <td>442.224070</td>\n",
              "      <td>429.925843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <td>2.894325</td>\n",
              "      <td>0.803145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HalfBath</th>\n",
              "      <td>0.382583</td>\n",
              "      <td>0.498195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <td>5.690802</td>\n",
              "      <td>47.795990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <td>1.045010</td>\n",
              "      <td>0.221139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OverallCond</th>\n",
              "      <td>5.562622</td>\n",
              "      <td>1.118578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MoSold</th>\n",
              "      <td>6.300391</td>\n",
              "      <td>2.709721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <td>47.127202</td>\n",
              "      <td>157.953692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <td>1984.698630</td>\n",
              "      <td>20.505826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YearBuilt</th>\n",
              "      <td>1970.940313</td>\n",
              "      <td>30.242334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <td>6.548924</td>\n",
              "      <td>1.615623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <td>0.056751</td>\n",
              "      <td>0.235674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageCars</th>\n",
              "      <td>1.764188</td>\n",
              "      <td>0.734066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ScreenPorch</th>\n",
              "      <td>15.646771</td>\n",
              "      <td>56.236989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageArea</th>\n",
              "      <td>469.398239</td>\n",
              "      <td>208.810654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FullBath</th>\n",
              "      <td>1.576321</td>\n",
              "      <td>0.541651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YrSold</th>\n",
              "      <td>2007.839530</td>\n",
              "      <td>1.341598</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       mean           std\n",
              "OverallQual        6.079256      1.357888\n",
              "WoodDeckSF        94.852250    128.397120\n",
              "Fireplaces         0.612524      0.635668\n",
              "MiscVal           55.864971    587.302105\n",
              "GrLivArea       1522.137965    517.810449\n",
              "LotFrontage       69.668667     20.832633\n",
              "PoolArea           1.786693     33.345922\n",
              "EnclosedPorch     23.607632     64.275741\n",
              "3SsnPorch          3.325832     28.732385\n",
              "1stFlrSF        1161.722114    373.986135\n",
              "2ndFlrSF         354.725049    440.838061\n",
              "TotalBsmtSF     1055.343444    410.235424\n",
              "MasVnrArea       103.553589    181.168466\n",
              "BsmtFullBath       0.418787      0.514966\n",
              "LotArea        10567.966732  10291.276619\n",
              "BsmtUnfSF        565.992172    433.040509\n",
              "GarageYrBlt     1978.012397     24.316390\n",
              "OpenPorchSF       47.378669     67.628982\n",
              "BsmtFinSF1       442.224070    429.925843\n",
              "BedroomAbvGr       2.894325      0.803145\n",
              "HalfBath           0.382583      0.498195\n",
              "LowQualFinSF       5.690802     47.795990\n",
              "KitchenAbvGr       1.045010      0.221139\n",
              "OverallCond        5.562622      1.118578\n",
              "MoSold             6.300391      2.709721\n",
              "BsmtFinSF2        47.127202    157.953692\n",
              "YearRemodAdd    1984.698630     20.505826\n",
              "YearBuilt       1970.940313     30.242334\n",
              "TotRmsAbvGrd       6.548924      1.615623\n",
              "BsmtHalfBath       0.056751      0.235674\n",
              "GarageCars         1.764188      0.734066\n",
              "ScreenPorch       15.646771     56.236989\n",
              "GarageArea       469.398239    208.810654\n",
              "FullBath           1.576321      0.541651\n",
              "YrSold          2007.839530      1.341598"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5SiF8sXoIE1"
      },
      "source": [
        "normalizer = build_normalizer(X_train_imputed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA0Ghq5poMq7",
        "outputId": "3db602e4-01d9-4ea4-feb4-cb571337c408"
      },
      "source": [
        "print(normalizer.mean.numpy())\n",
        "print(normalizer.variance.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.0792565e+00 9.4852249e+01 6.1252445e-01 5.5864971e+01 1.5221379e+03\n",
            " 6.9668671e+01 1.7866927e+00 2.3607632e+01 3.3258317e+00 1.1617222e+03\n",
            " 3.5472504e+02 1.0553434e+03 1.0355359e+02 4.1878670e-01 1.0567967e+04\n",
            " 5.6599219e+02 1.9780125e+03 4.7378670e+01 4.4222406e+02 2.8943248e+00\n",
            " 3.8258317e-01 5.6908026e+00 1.0450097e+00 5.5626225e+00 6.3003912e+00\n",
            " 4.7127201e+01 1.9846986e+03 1.9709403e+03 6.5489235e+00 5.6751467e-02\n",
            " 1.7641878e+00 1.5646771e+01 4.6939822e+02 1.5763209e+00 2.0078395e+03]\n",
            "[1.84205508e+00 1.64696895e+04 4.03678745e-01 3.44586250e+05\n",
            " 2.67865312e+05 4.33573914e+02 1.11086255e+03 4.12732861e+03\n",
            " 8.24742188e+02 1.39728781e+05 1.94148047e+05 1.68128438e+05\n",
            " 3.27898984e+04 2.64930815e-01 1.05806744e+08 1.87340594e+05\n",
            " 5.90708252e+02 4.56920410e+03 1.84655375e+05 6.44410074e-01\n",
            " 2.47954965e-01 2.28222144e+03 4.88547459e-02 1.24999237e+00\n",
            " 7.33540106e+00 2.49249570e+04 4.20077484e+02 9.13703857e+02\n",
            " 2.60768485e+00 5.54876849e-02 5.38326085e-01 3.15950439e+03\n",
            " 4.35592266e+04 2.93098807e-01 1.79812419e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJSMEbdAAG8p",
        "outputId": "b14135c2-19b5-41a9-eabc-1d5e3eec6064"
      },
      "source": [
        "normalizer(np.array(X_train_imputed[:1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 35), dtype=float32, numpy=\n",
              "array([[ 0.67840236,  3.7491755 , -0.9640632 , -0.09516793,  0.9889964 ,\n",
              "         0.        , -0.05360678, -0.3674666 , -0.1158087 , -0.28015327,\n",
              "         1.4122639 ,  0.00404019,  2.5924835 ,  1.1291959 , -0.11597695,\n",
              "        -0.57295704,  0.8223809 , -0.16833374,  0.6906336 ,  0.13164125,\n",
              "         1.2399155 , -0.11912273, -0.20363528, -0.50322646, -1.5878009 ,\n",
              "        -0.29850698,  0.6489816 ,  0.8621177 ,  0.8985924 , -0.24092332,\n",
              "         0.3213983 , -0.2783654 ,  0.8413735 ,  0.7825823 ,  0.8654534 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehJnd_j3sRLk"
      },
      "source": [
        "#### Model Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuCqfQjOsSRe",
        "outputId": "ad90e297-9d80-4176-f22e-534aab6794ba"
      },
      "source": [
        "models[simple_handle] = tf.keras.Sequential([\n",
        "  normalizer,\n",
        "  layers.Dense(16, activation='relu'),\n",
        "  layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "models[simple_handle].summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 35)                71        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                576       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 664\n",
            "Trainable params: 593\n",
            "Non-trainable params: 71\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vpiPKmIsgtQ"
      },
      "source": [
        "models[simple_handle].compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "                              loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeC1mKoBsr7W"
      },
      "source": [
        "model_histories[simple_handle] = models[simple_handle].fit(X_train_imputed, y_train,\n",
        "                                                           epochs=1000,\n",
        "                                                           validation_split=0.2,\n",
        "                                                           verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UZozZVc-tF0q",
        "outputId": "5b7071d5-7659-4215-faa4-4e6773c6a5b5"
      },
      "source": [
        "def plot_losses(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title(\"Learning Curves\")\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "plot_losses(model_histories[simple_handle])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYTDxtm4tXgD",
        "outputId": "ef61b94d-7f54-41fd-cfe6-8398f385d84d"
      },
      "source": [
        "model_evaluations[simple_handle] = models[simple_handle].evaluate(X_valid_imputed, y_valid)\n",
        "print(model_evaluations[simple_handle])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 1ms/step - loss: 1424932480.0000\n",
            "1424932480.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "Cd3X0M6-5mWF",
        "outputId": "3a08ba83-d0ee-48c6-adaf-f58a727ace66"
      },
      "source": [
        "X_test_imputed = pd.DataFrame(impute.transform(X_test[numerical_cols]), columns=numerical_cols)\n",
        "X_test_imputed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>YrSold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>896.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>896.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>882.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11622.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>1961.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>468.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1961.0</td>\n",
              "      <td>1961.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>730.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2010.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.0</td>\n",
              "      <td>393.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12500.0</td>\n",
              "      <td>1329.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1329.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1329.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14267.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>1958.000000</td>\n",
              "      <td>36.0</td>\n",
              "      <td>923.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1958.0</td>\n",
              "      <td>1958.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2010.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1629.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>928.0</td>\n",
              "      <td>701.0</td>\n",
              "      <td>928.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13830.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>1997.000000</td>\n",
              "      <td>34.0</td>\n",
              "      <td>791.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>482.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2010.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1604.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>926.0</td>\n",
              "      <td>678.0</td>\n",
              "      <td>926.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9978.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>1998.000000</td>\n",
              "      <td>36.0</td>\n",
              "      <td>602.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2010.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1280.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1280.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1280.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5005.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>1992.000000</td>\n",
              "      <td>82.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1992.0</td>\n",
              "      <td>1992.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2010.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1092.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1936.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>1978.012397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1092.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1894.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>1970.000000</td>\n",
              "      <td>24.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>5.0</td>\n",
              "      <td>474.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1224.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1224.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1224.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1960.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1224.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>1960.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>576.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>5.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>970.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>970.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>912.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10441.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>1978.012397</td>\n",
              "      <td>32.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1992.0</td>\n",
              "      <td>1992.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>7.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>996.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>996.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9627.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>1993.000000</td>\n",
              "      <td>48.0</td>\n",
              "      <td>758.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1994.0</td>\n",
              "      <td>1993.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>650.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1459 rows × 35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      OverallQual  WoodDeckSF  Fireplaces  ...  GarageArea  FullBath  YrSold\n",
              "0             5.0       140.0         0.0  ...       730.0       1.0  2010.0\n",
              "1             6.0       393.0         0.0  ...       312.0       1.0  2010.0\n",
              "2             5.0       212.0         1.0  ...       482.0       2.0  2010.0\n",
              "3             6.0       360.0         1.0  ...       470.0       2.0  2010.0\n",
              "4             8.0         0.0         0.0  ...       506.0       2.0  2010.0\n",
              "...           ...         ...         ...  ...         ...       ...     ...\n",
              "1454          4.0         0.0         0.0  ...         0.0       1.0  2006.0\n",
              "1455          4.0         0.0         0.0  ...       286.0       1.0  2006.0\n",
              "1456          5.0       474.0         1.0  ...       576.0       1.0  2006.0\n",
              "1457          5.0        80.0         0.0  ...         0.0       1.0  2006.0\n",
              "1458          7.0       190.0         1.0  ...       650.0       2.0  2006.0\n",
              "\n",
              "[1459 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oUP_9Vi5x3N",
        "outputId": "7b122bd7-3c1a-469a-8dfa-122d48a2b8fc"
      },
      "source": [
        "y_preds = models[simple_handle].predict(X_test_imputed)\n",
        "y_preds.flatten()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([127900.484, 155758.7  , 172525.45 , ..., 195817.52 , 103353.84 ,\n",
              "       241812.17 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOxn4cyV56JD"
      },
      "source": [
        "output = pd.DataFrame({'Id': X_test.index, 'SalePrice': y_preds.flatten() })\n",
        "output.to_csv(workdir + '/ann-submission1.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}